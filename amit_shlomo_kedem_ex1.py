# -*- coding: utf-8 -*-
"""amit_Shlomo_kedem_ex1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cri4ja1GZa3pjx-Ceq_HlmGtTbl0_syC

# This is formatted as code

Student 1: name: Amit Shlomo Kedem, i.d.: 315216663, github: https://github.com/amitkedem/machine-learning-task-1


Student 2: name: Ido Abodi Amarteli, i.d.: 209306323, github: https://github.com/Idoamarteli20/Machine-learning-task-1/upload


Student 3: name: Daniel Cohen, i.d.: 318974391, github: https://github.com/danielcohen0121/machine-learning-task-1

1. Load breast cancer dataset (**structured data**)

For more details about the data: https://scikit-learn.org/1.5/modules/generated/sklearn.datasets.load_breast_cancer.html
"""

'''
in this part we load the module we want to research, in this project - breast cancer.
the data is being imported from sklearn.datasets (it contains various resarches (fires,brain cancer, false pregnancies))
'''
from sklearn.datasets import load_breast_cancer
my_data = load_breast_cancer()

"""2. Split **my_data** to train and test:

- Define X_train, X_test, Y_train, Y_test
- Choose **test_size** for splitting **my_data**
- Use **train_test_split** (for details: https://scikit-learn.org/dev/modules/generated/sklearn.model_selection.train_test_split.html)
"""

from sklearn.model_selection import train_test_split

X = my_data.data
y = my_data.target
'''
In this part we divide the data we recieved in the import section, we always divide it to
x train,test , y train,test. in the () we decide the test size (the most common is 0.2 for testing, and 0.8 for training)
random state is used so we will recieve the same data structure (testing <-> training every time we run the notebook.
we can choose every number but it's important to use the same number every time.
'''
X_train, X_test, Y_train, Y_test = train_test_split(X,y, test_size=0.2,random_state=42)

"""3. Libraries"""

'''
This is the imports that we need to be able to train the module -
we do not touch that part and it's forbidden to change it (Per Igor's request).
'''
!pip install mlflow
!pip install mlflow scikit-learn

import mlflow
import mlflow.sklearn
from mlflow import log_param, log_metric

from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score

import itertools
import pandas as pd

"""4. Define MLFlow experiment"""

'''
MLFlow Is a tool to monitor and track the results of our training sessions.
you can see how it works in code block 5.1
'''
EXPERIMENT_NAME = "trees_hyperparam"
mlflow.set_experiment(EXPERIMENT_NAME)
# MLFlow details: https://mlflow.org/docs/latest/ml/tracking/

"""5. Train **model_decision_tree**

- Library: sklearn.tree.DecisionTreeClassifier
- Data: X_train, Y_train
- **Essential**: explore and optimize DecisionTreeClassifier options   
"""

from sklearn.tree import DecisionTreeClassifier

'''
This part defines the parameters we want to check.
since DecisionTreeClassifier expects variavbles (or None). we decided to give him 3 variables, based on params_x_list
It's important to remember :
x = Features about the current subject
Y = binary assunption (0/1) in our case - breast cancer 0 - Not a tumor, 1 = Real tumor
in this project - the params we currently use are - max_depth (param_1), min_samples_split (param_2) and criterion (param_3)
(took the most common from the docs)
'''

'''
param_1_list : here - we decide the depth of the tree that we want to check. (None == Unlimited)
param_2_list : here we decide what is the mininum number of samples that a node must have before splitting into 2 childs.
               this param must be > 1 because you need at least 2 samples to be able to split them into 2 groups.
param_3_list : for criterion - there are only 2 options.
               and we chose to use both in order to get as many results as possible (the more the better :) )
               * Gini -  measures how mixed the classes are inside a node.
               * entropy - measures uncertainty in a node — coming from information theory.
'''

param_1_list =[1,2,3,4,5,6,7,8,9,None]
param_2_list = [2,3,4,5,6,7,8,9]
param_3_list = ["gini","entropy"]

'''
In this part - we create param_grid - which generates all possible combinations of parameters
so if for example - if my data is :
x = 1,2,3
y = 3,4,5
z = 6,7,8

i will get
x1,y1,z1 = 1,3,6
x2,y2,z2 = 2,4,7
x3,y3,z3 = 3,5,8
and so on, untill all is covered.
'''
param_grid = list(itertools.product(param_1_list, param_2_list, param_3_list))

'''
here - we actually start to train the model !
each time we take a differnt param from the grid, and iterate the entire grid ^
'''
for param_1, param_2, param_3 in param_grid:
    with mlflow.start_run():

        '''
        this part is perhaps the most imporant in the training session - Because altough we are able to train our model without it -
        if we dont log the params - we won't be able to tell which combination from the grid produced the best score !
        '''
        # Log parameters
        mlflow.log_param("model_type", "DecisionTree")
        mlflow.log_param("param_1", param_1)
        mlflow.log_param("param_2", param_2)
        mlflow.log_param("param_3", param_3)
        '''
        Here - the training begin !
        the function DecisionTreeClassifier has a lot of options, and it is up to us to decide what to give it,
        since we took max_depth, min_samples_split and criterion - we will give it to the function and and each time provide a param from the loop.
        '''
        # Train the model
        d_tree = DecisionTreeClassifier(max_depth=param_1, min_samples_split=param_2, criterion=param_3)
        d_tree.fit(X_train, Y_train)
        pred = d_tree.predict(X_test)
        '''
        this part calculate the "scores" for the current iteration (in terms of accuracy, precision and recall)
        * acc - Out of ALL predictions, how many did the model get right?
        * pre - How many “positive” predictions were actually correct?
        * rec - How many actual positive cases did we successfully catch?
        * f1 -  Balance between precision and recall

        '''
        acc  = accuracy_score(Y_test, pred)
        pre = precision_score(Y_test, pred)
        rec  = recall_score(Y_test, pred)
        f1   = f1_score(Y_test, pred)


        # run test prediction and calculate metrics:
        # accuracy_score
        # precision_score
        # recall_score
        # f1_score

        '''
        Here - we simply log the results to the mlflow.
        we do it in order to observe and look at the results the training session produced.
        we can see how it is logged in the next code block :)
        '''
        # Log metrics
        mlflow.log_metric("accuracy", acc)
        mlflow.log_metric("precision_score", pre)
        mlflow.log_metric("recall_score", rec)
        mlflow.log_metric("f1_score", f1)

"""6. Train model_random_forest
- Library: sklearn.ensemble.RandomForestClassifier
- Data: X_train, Y_train
- **Essential**: explore and optimize RandomForestClassifier options
"""

from sklearn.ensemble import RandomForestClassifier

'''
Random forest works technically the same as decisionTree in terms of params.
it can recieve a lot of different params, I decided to take the most common 3 (from the docs)
* param_1_list = n_estimators : Number of trees in the forest
* param_2_list = max_depth : depth limit in each tree where None = Infinity
* param_3_list = max_features : How many features each tree can use per split.

'''
param_1_list = [1, 5, 10, 50, 100, 200, 500, 1000]
param_2_list = [1,2,3,4,5,6,7,8,9,None]
param_3_list = ["sqrt", "log2"]

'''
Same as Decision tree - we recieve a grid with all possible combinations.
'''
param_grid = list(itertools.product(param_1_list, param_2_list, param_3_list))

for param_1, param_2, param_3 in param_grid:
    with mlflow.start_run():

        # Log parameters
        mlflow.log_param("model_type", "RandomForest")
        mlflow.log_param("param_1", param_1)
        mlflow.log_param("param_2", param_2)
        mlflow.log_param("param_3", param_3)

        # Train the model
        rf = RandomForestClassifier(n_estimators=param_1, max_depth=param_2, max_features=param_3)
        rf.fit(X_train, Y_train)
        pred = rf.predict(X_test)



        # run test prediction and calculate metrics:
        # accuracy_score
        # precision_score
        # recall_score
        # f1_score
        acc  = accuracy_score(Y_test, pred)
        pre = precision_score(Y_test, pred)
        rec  = recall_score(Y_test, pred)
        f1   = f1_score(Y_test, pred)


        # Log metrics
        mlflow.log_metric("accuracy", acc)
        mlflow.log_metric("precision_score", pre)
        mlflow.log_metric("recall_score", rec)
        mlflow.log_metric("f1_score", f1)

"""7. Train model_adaboost

- Library: sklearn.ensemble.AdaBoostClassifier
- Data: X_train, Y_train
- **Essential**: explore and optimize AdaBoostClassifier options
"""

from sklearn.ensemble import AdaBoostClassifier
'''
Same as DecisionTree and RandomForest - AdaBoost accept various args.
I chose the most common args to pick
which are -
n_estimators
learning_rate
estimator__min_samples_split
'''

param_1_list = [1, 5, 10, 50, 100, 200, 500, 1000]
param_2_list = [0.01, 0.1, 1.0]
param_3_list = [2,5,10]

param_grid = list(itertools.product(param_1_list, param_2_list, param_3_list))
for param_1, param_2, param_3 in param_grid:
    with mlflow.start_run():

        # Log parameters
        mlflow.log_param("model_type", "AdaBoost")
        mlflow.log_param("param_1", param_1)
        mlflow.log_param("param_2", param_2)
        mlflow.log_param("param_3", param_3)
        '''
        This is a tricky part - param3 is being used from DecisionTree, so when we parse it - we can't simply say estimator=param3.
        we need to tell AdaBoostClassifier that we are using a param from DecisionTree
        '''
        ada = AdaBoostClassifier(n_estimators=param_1, learning_rate=param_2, estimator=DecisionTreeClassifier(min_samples_split=param_3))
        ada.fit(X_train, Y_train)
        pred = ada.predict(X_test)

        # run test prediction and calculate metrics:
        # accuracy_score
        # precision_score
        # recall_score
        # f1_score
        acc  = accuracy_score(Y_test, pred)
        pre = precision_score(Y_test, pred)
        rec  = recall_score(Y_test, pred)
        f1   = f1_score(Y_test, pred)


        # Log metrics
        mlflow.log_metric("accuracy", acc)
        mlflow.log_metric("precision_score", pre)
        mlflow.log_metric("recall_score", rec)
        mlflow.log_metric("f1_score", f1)

"""8. Store the result"""

from google.colab import files

df = mlflow.search_runs(experiment_names=["trees_hyperparam"])

df = df.drop(columns=[col for col in df.columns if "time" in col.lower()], errors="ignore")

df.to_excel("student_name_results.xlsx", index=False)

files.download("student_name_results.xlsx")