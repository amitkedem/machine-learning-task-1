{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtraKe7-wRJr"
      },
      "source": [
        "# This is formatted as code\n",
        "\n",
        "Student 1: name: Amit Shlomo Kedem, i.d.: 315216663, github: https://github.com/amitkedem/machine-learning-task-1\n",
        "\n",
        "\n",
        "Student 2: name: Ido Abodi Amarteli, i.d.: 209306323, github: https://github.com/Idoamarteli20/Machine-learning-task-1/upload\n",
        "\n",
        "\n",
        "Student 3: name: Daniel Cohen, i.d.: 318974391, github: https://github.com/danielcohen0121/machine-learning-task-1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1I0ncvTh3x8"
      },
      "source": [
        "1. Load breast cancer dataset (**structured data**)\n",
        "\n",
        "For more details about the data: https://scikit-learn.org/1.5/modules/generated/sklearn.datasets.load_breast_cancer.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2sS2vcbN3MRc"
      },
      "outputs": [],
      "source": [
        "\n",
        "'''\n",
        "in this part we load the module we want to research, in this project - breast cancer.\n",
        "the data is being imported from sklearn.datasets (it contains various resarches (fires,brain cancer, false pregnancies))\n",
        "'''\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "my_data = load_breast_cancer()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCHHt_25iA_4"
      },
      "source": [
        "2. Split **my_data** to train and test:\n",
        "\n",
        "- Define X_train, X_test, Y_train, Y_test\n",
        "- Choose **test_size** for splitting **my_data**\n",
        "- Use **train_test_split** (for details: https://scikit-learn.org/dev/modules/generated/sklearn.model_selection.train_test_split.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "V8CpCqnGmCg2"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = my_data.data\n",
        "y = my_data.target\n",
        "'''\n",
        "In this part we divide the data we recieved in the import section, we always divide it to\n",
        "x train,test , y train,test. in the () we decide the test size (the most common is 0.2 for testing, and 0.8 for training)\n",
        "random state is used so we will recieve the same data structure (testing <-> training every time we run the notebook.\n",
        "we can choose every number but it's important to use the same number every time.\n",
        "'''\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,y, test_size=0.2,random_state=42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVwASy_zG8Kq"
      },
      "source": [
        "3. Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trHR283WjwFR",
        "outputId": "aa4cdfc7-f338-419c-cc3b-63b368e12404",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mlflow\n",
            "  Downloading mlflow-3.7.0-py3-none-any.whl.metadata (31 kB)\n",
            "Collecting mlflow-skinny==3.7.0 (from mlflow)\n",
            "  Downloading mlflow_skinny-3.7.0-py3-none-any.whl.metadata (31 kB)\n",
            "Collecting mlflow-tracing==3.7.0 (from mlflow)\n",
            "  Downloading mlflow_tracing-3.7.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting Flask-CORS<7 (from mlflow)\n",
            "  Downloading flask_cors-6.0.2-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.12/dist-packages (from mlflow) (3.1.2)\n",
            "Requirement already satisfied: alembic!=1.10.0,<2 in /usr/local/lib/python3.12/dist-packages (from mlflow) (1.17.2)\n",
            "Requirement already satisfied: cryptography<47,>=43.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow) (43.0.3)\n",
            "Collecting docker<8,>=4.0.0 (from mlflow)\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting graphene<4 (from mlflow)\n",
            "  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting gunicorn<24 (from mlflow)\n",
            "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting huey<3,>=2.5.0 (from mlflow)\n",
            "  Downloading huey-2.5.5-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.12/dist-packages (from mlflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<3 in /usr/local/lib/python3.12/dist-packages (from mlflow) (2.0.2)\n",
            "Requirement already satisfied: pandas<3 in /usr/local/lib/python3.12/dist-packages (from mlflow) (2.2.2)\n",
            "Requirement already satisfied: pyarrow<23,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow) (18.1.0)\n",
            "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.12/dist-packages (from mlflow) (1.6.1)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.12/dist-packages (from mlflow) (1.16.3)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from mlflow) (2.0.44)\n",
            "Requirement already satisfied: cachetools<7,>=5.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.7.0->mlflow) (6.2.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.7.0->mlflow) (8.3.1)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.7.0->mlflow) (3.1.2)\n",
            "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==3.7.0->mlflow)\n",
            "  Downloading databricks_sdk-0.74.0-py3-none-any.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fastapi<1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.7.0->mlflow) (0.118.3)\n",
            "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.7.0->mlflow) (3.1.45)\n",
            "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.7.0->mlflow) (8.7.0)\n",
            "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.7.0->mlflow) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-proto<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.7.0->mlflow) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.7.0->mlflow) (1.37.0)\n",
            "Requirement already satisfied: packaging<26 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.7.0->mlflow) (25.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.12.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.7.0->mlflow) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.7.0->mlflow) (2.12.3)\n",
            "Requirement already satisfied: python-dotenv<2,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.7.0->mlflow) (1.2.1)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.7.0->mlflow) (6.0.3)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.7.0->mlflow) (2.32.4)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.7.0->mlflow) (0.5.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.7.0->mlflow) (4.15.0)\n",
            "Requirement already satisfied: uvicorn<1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.7.0->mlflow) (0.38.0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic!=1.10.0,<2->mlflow) (1.3.10)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography<47,>=43.0.0->mlflow) (2.0.0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from docker<8,>=4.0.0->mlflow) (2.5.0)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (1.9.0)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (3.0.3)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (3.1.4)\n",
            "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_core-3.2.7-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.0 in /usr/local/lib/python3.12/dist-packages (from graphene<4->mlflow) (2.9.0.post0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (4.61.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (3.2.5)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3->mlflow) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3->mlflow) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<2->mlflow) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<2->mlflow) (3.6.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.3.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography<47,>=43.0.0->mlflow) (2.23)\n",
            "Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.12/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.7.0->mlflow) (2.43.0)\n",
            "Requirement already satisfied: starlette<0.49.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi<1->mlflow-skinny==3.7.0->mlflow) (0.48.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.7.0->mlflow) (4.0.12)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.7.0->mlflow) (3.23.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.7.0->mlflow) (0.58b0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.7.0->mlflow) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.7.0->mlflow) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.7.0->mlflow) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.7.0->mlflow) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.7.0->mlflow) (3.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.7.0->mlflow) (2025.11.12)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn<1->mlflow-skinny==3.7.0->mlflow) (0.16.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.7.0->mlflow) (5.0.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.7.0->mlflow) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.7.0->mlflow) (4.9.1)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.12/dist-packages (from starlette<0.49.0,>=0.40.0->fastapi<1->mlflow-skinny==3.7.0->mlflow) (4.12.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.7.0->mlflow) (0.6.1)\n",
            "Downloading mlflow-3.7.0-py3-none-any.whl (8.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlflow_skinny-3.7.0-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlflow_tracing-3.7.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading flask_cors-6.0.2-py3-none-any.whl (13 kB)\n",
            "Downloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huey-2.5.5-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading databricks_sdk-0.74.0-py3-none-any.whl (764 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m764.2/764.2 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_core-3.2.7-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
            "Installing collected packages: huey, gunicorn, graphql-core, graphql-relay, docker, graphene, Flask-CORS, databricks-sdk, mlflow-tracing, mlflow-skinny, mlflow\n",
            "Successfully installed Flask-CORS-6.0.2 databricks-sdk-0.74.0 docker-7.1.0 graphene-3.4.3 graphql-core-3.2.7 graphql-relay-3.2.0 gunicorn-23.0.0 huey-2.5.5 mlflow-3.7.0 mlflow-skinny-3.7.0 mlflow-tracing-3.7.0\n",
            "Requirement already satisfied: mlflow in /usr/local/lib/python3.12/dist-packages (3.7.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: mlflow-skinny==3.7.0 in /usr/local/lib/python3.12/dist-packages (from mlflow) (3.7.0)\n",
            "Requirement already satisfied: mlflow-tracing==3.7.0 in /usr/local/lib/python3.12/dist-packages (from mlflow) (3.7.0)\n",
            "Requirement already satisfied: Flask-CORS<7 in /usr/local/lib/python3.12/dist-packages (from mlflow) (6.0.2)\n",
            "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.12/dist-packages (from mlflow) (3.1.2)\n",
            "Requirement already satisfied: alembic!=1.10.0,<2 in /usr/local/lib/python3.12/dist-packages (from mlflow) (1.17.2)\n",
            "Requirement already satisfied: cryptography<47,>=43.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow) (43.0.3)\n",
            "Requirement already satisfied: docker<8,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow) (7.1.0)\n",
            "Requirement already satisfied: graphene<4 in /usr/local/lib/python3.12/dist-packages (from mlflow) (3.4.3)\n",
            "Requirement already satisfied: gunicorn<24 in /usr/local/lib/python3.12/dist-packages (from mlflow) (23.0.0)\n",
            "Requirement already satisfied: huey<3,>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from mlflow) (2.5.5)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.12/dist-packages (from mlflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<3 in /usr/local/lib/python3.12/dist-packages (from mlflow) (2.0.2)\n",
            "Requirement already satisfied: pandas<3 in /usr/local/lib/python3.12/dist-packages (from mlflow) (2.2.2)\n",
            "Requirement already satisfied: pyarrow<23,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow) (18.1.0)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.12/dist-packages (from mlflow) (1.16.3)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from mlflow) (2.0.44)\n",
            "Requirement already satisfied: cachetools<7,>=5.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.7.0->mlflow) (6.2.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.7.0->mlflow) (8.3.1)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.7.0->mlflow) (3.1.2)\n",
            "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.7.0->mlflow) (0.74.0)\n",
            "Requirement already satisfied: fastapi<1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.7.0->mlflow) (0.118.3)\n",
            "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.7.0->mlflow) (3.1.45)\n",
            "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.7.0->mlflow) (8.7.0)\n",
            "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.7.0->mlflow) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-proto<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.7.0->mlflow) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.7.0->mlflow) (1.37.0)\n",
            "Requirement already satisfied: packaging<26 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.7.0->mlflow) (25.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.12.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.7.0->mlflow) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.7.0->mlflow) (2.12.3)\n",
            "Requirement already satisfied: python-dotenv<2,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.7.0->mlflow) (1.2.1)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.7.0->mlflow) (6.0.3)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.7.0->mlflow) (2.32.4)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.7.0->mlflow) (0.5.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.7.0->mlflow) (4.15.0)\n",
            "Requirement already satisfied: uvicorn<1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.7.0->mlflow) (0.38.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic!=1.10.0,<2->mlflow) (1.3.10)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography<47,>=43.0.0->mlflow) (2.0.0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from docker<8,>=4.0.0->mlflow) (2.5.0)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (1.9.0)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (3.0.3)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (3.1.4)\n",
            "Requirement already satisfied: graphql-core<3.3,>=3.1 in /usr/local/lib/python3.12/dist-packages (from graphene<4->mlflow) (3.2.7)\n",
            "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /usr/local/lib/python3.12/dist-packages (from graphene<4->mlflow) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.0 in /usr/local/lib/python3.12/dist-packages (from graphene<4->mlflow) (2.9.0.post0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (4.61.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (3.2.5)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3->mlflow) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3->mlflow) (2025.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.3.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography<47,>=43.0.0->mlflow) (2.23)\n",
            "Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.12/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.7.0->mlflow) (2.43.0)\n",
            "Requirement already satisfied: starlette<0.49.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi<1->mlflow-skinny==3.7.0->mlflow) (0.48.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.7.0->mlflow) (4.0.12)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.7.0->mlflow) (3.23.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.7.0->mlflow) (0.58b0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.7.0->mlflow) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.7.0->mlflow) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.7.0->mlflow) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.7.0->mlflow) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.7.0->mlflow) (3.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.7.0->mlflow) (2025.11.12)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn<1->mlflow-skinny==3.7.0->mlflow) (0.16.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.7.0->mlflow) (5.0.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.7.0->mlflow) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.7.0->mlflow) (4.9.1)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.12/dist-packages (from starlette<0.49.0,>=0.40.0->fastapi<1->mlflow-skinny==3.7.0->mlflow) (4.12.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.7.0->mlflow) (0.6.1)\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "This is the imports that we need to be able to train the module -\n",
        "we do not touch that part and it's forbidden to change it (Per Igor's request).\n",
        "'''\n",
        "!pip install mlflow\n",
        "!pip install mlflow scikit-learn\n",
        "\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "from mlflow import log_param, log_metric\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "import itertools\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1lvKRu3lCu2"
      },
      "source": [
        "4. Define MLFlow experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhwmWNz6lIuf",
        "outputId": "710d6c5c-8eb5-46a2-8780-846db24c370f",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/12/14 14:25:34 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
            "2025/12/14 14:25:34 INFO mlflow.store.db.utils: Updating database tables\n",
            "2025/12/14 14:25:34 INFO alembic.runtime.migration: Context impl SQLiteImpl.\n",
            "2025/12/14 14:25:34 INFO alembic.runtime.migration: Will assume non-transactional DDL.\n",
            "2025/12/14 14:25:35 INFO alembic.runtime.migration: Running upgrade  -> 451aebb31d03, add metric step\n",
            "2025/12/14 14:25:35 INFO alembic.runtime.migration: Running upgrade 451aebb31d03 -> 90e64c465722, migrate user column to tags\n",
            "2025/12/14 14:25:35 INFO alembic.runtime.migration: Running upgrade 90e64c465722 -> 181f10493468, allow nulls for metric values\n",
            "2025/12/14 14:25:35 INFO alembic.runtime.migration: Running upgrade 181f10493468 -> df50e92ffc5e, Add Experiment Tags Table\n",
            "2025/12/14 14:25:35 INFO alembic.runtime.migration: Running upgrade df50e92ffc5e -> 7ac759974ad8, Update run tags with larger limit\n",
            "2025/12/14 14:25:35 INFO alembic.runtime.migration: Running upgrade 7ac759974ad8 -> 89d4b8295536, create latest metrics table\n",
            "2025/12/14 14:25:35 INFO alembic.runtime.migration: Running upgrade 89d4b8295536 -> 2b4d017a5e9b, add model registry tables to db\n",
            "2025/12/14 14:25:35 INFO alembic.runtime.migration: Running upgrade 2b4d017a5e9b -> cfd24bdc0731, Update run status constraint with killed\n",
            "2025/12/14 14:25:36 INFO alembic.runtime.migration: Running upgrade cfd24bdc0731 -> 0a8213491aaa, drop_duplicate_killed_constraint\n",
            "2025/12/14 14:25:36 INFO alembic.runtime.migration: Running upgrade 0a8213491aaa -> 728d730b5ebd, add registered model tags table\n",
            "2025/12/14 14:25:36 INFO alembic.runtime.migration: Running upgrade 728d730b5ebd -> 27a6a02d2cf1, add model version tags table\n",
            "2025/12/14 14:25:36 INFO alembic.runtime.migration: Running upgrade 27a6a02d2cf1 -> 84291f40a231, add run_link to model_version\n",
            "2025/12/14 14:25:36 INFO alembic.runtime.migration: Running upgrade 84291f40a231 -> a8c4a736bde6, allow nulls for run_id\n",
            "2025/12/14 14:25:36 INFO alembic.runtime.migration: Running upgrade a8c4a736bde6 -> 39d1c3be5f05, add_is_nan_constraint_for_metrics_tables_if_necessary\n",
            "2025/12/14 14:25:36 INFO alembic.runtime.migration: Running upgrade 39d1c3be5f05 -> c48cb773bb87, reset_default_value_for_is_nan_in_metrics_table_for_mysql\n",
            "2025/12/14 14:25:36 INFO alembic.runtime.migration: Running upgrade c48cb773bb87 -> bd07f7e963c5, create index on run_uuid\n",
            "2025/12/14 14:25:36 INFO alembic.runtime.migration: Running upgrade bd07f7e963c5 -> 0c779009ac13, add deleted_time field to runs table\n",
            "2025/12/14 14:25:36 INFO alembic.runtime.migration: Running upgrade 0c779009ac13 -> cc1f77228345, change param value length to 500\n",
            "2025/12/14 14:25:36 INFO alembic.runtime.migration: Running upgrade cc1f77228345 -> 97727af70f4d, Add creation_time and last_update_time to experiments table\n",
            "2025/12/14 14:25:36 INFO alembic.runtime.migration: Running upgrade 97727af70f4d -> 3500859a5d39, Add Model Aliases table\n",
            "2025/12/14 14:25:36 INFO alembic.runtime.migration: Running upgrade 3500859a5d39 -> 7f2a7d5fae7d, add datasets inputs input_tags tables\n",
            "2025/12/14 14:25:36 INFO alembic.runtime.migration: Running upgrade 7f2a7d5fae7d -> 2d6e25af4d3e, increase max param val length from 500 to 8000\n",
            "2025/12/14 14:25:36 INFO alembic.runtime.migration: Running upgrade 2d6e25af4d3e -> acf3f17fdcc7, add storage location field to model versions\n",
            "2025/12/14 14:25:37 INFO alembic.runtime.migration: Running upgrade acf3f17fdcc7 -> 867495a8f9d4, add trace tables\n",
            "2025/12/14 14:25:37 INFO alembic.runtime.migration: Running upgrade 867495a8f9d4 -> 5b0e9adcef9c, add cascade deletion to trace tables foreign keys\n",
            "2025/12/14 14:25:37 INFO alembic.runtime.migration: Running upgrade 5b0e9adcef9c -> 4465047574b1, increase max dataset schema size\n",
            "2025/12/14 14:25:37 INFO alembic.runtime.migration: Running upgrade 4465047574b1 -> f5a4f2784254, increase run tag value limit to 8000\n",
            "2025/12/14 14:25:37 INFO alembic.runtime.migration: Running upgrade f5a4f2784254 -> 0584bdc529eb, add cascading deletion to datasets from experiments\n",
            "2025/12/14 14:25:37 INFO alembic.runtime.migration: Running upgrade 0584bdc529eb -> 400f98739977, add logged model tables\n",
            "2025/12/14 14:25:37 INFO alembic.runtime.migration: Running upgrade 400f98739977 -> 6953534de441, add step to inputs table\n",
            "2025/12/14 14:25:37 INFO alembic.runtime.migration: Running upgrade 6953534de441 -> bda7b8c39065, increase_model_version_tag_value_limit\n",
            "2025/12/14 14:25:37 INFO alembic.runtime.migration: Running upgrade bda7b8c39065 -> cbc13b556ace, add V3 trace schema columns\n",
            "2025/12/14 14:25:37 INFO alembic.runtime.migration: Running upgrade cbc13b556ace -> 770bee3ae1dd, add assessments table\n",
            "2025/12/14 14:25:38 INFO alembic.runtime.migration: Running upgrade 770bee3ae1dd -> a1b2c3d4e5f6, add spans table\n",
            "2025/12/14 14:25:38 INFO alembic.runtime.migration: Running upgrade a1b2c3d4e5f6 -> de4033877273, create entity_associations table\n",
            "2025/12/14 14:25:38 INFO alembic.runtime.migration: Running upgrade de4033877273 -> 1a0cddfcaa16, Add webhooks and webhook_events tables\n",
            "2025/12/14 14:25:38 INFO alembic.runtime.migration: Running upgrade 1a0cddfcaa16 -> 534353b11cbc, add scorer tables\n",
            "2025/12/14 14:25:38 INFO alembic.runtime.migration: Running upgrade 534353b11cbc -> 71994744cf8e, add evaluation datasets\n",
            "2025/12/14 14:25:38 INFO alembic.runtime.migration: Running upgrade 71994744cf8e -> 3da73c924c2f, add outputs to dataset record\n",
            "2025/12/14 14:25:38 INFO alembic.runtime.migration: Running upgrade 3da73c924c2f -> bf29a5ff90ea, add jobs table\n",
            "2025/12/14 14:25:38 INFO alembic.runtime.migration: Context impl SQLiteImpl.\n",
            "2025/12/14 14:25:38 INFO alembic.runtime.migration: Will assume non-transactional DDL.\n",
            "2025/12/14 14:25:38 INFO mlflow.tracking.fluent: Experiment with name 'trees_hyperparam' does not exist. Creating a new experiment.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Experiment: artifact_location='/content/mlruns/1', creation_time=1765722338787, experiment_id='1', last_update_time=1765722338787, lifecycle_stage='active', name='trees_hyperparam', tags={}>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "'''\n",
        "MLFlow Is a tool to monitor and track the results of our training sessions.\n",
        "you can see how it works in code block 5.1\n",
        "'''\n",
        "EXPERIMENT_NAME = \"trees_hyperparam\"\n",
        "mlflow.set_experiment(EXPERIMENT_NAME)\n",
        "# MLFlow details: https://mlflow.org/docs/latest/ml/tracking/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1_cFF_cjIyK"
      },
      "source": [
        "5. Train **model_decision_tree**\n",
        "\n",
        "- Library: sklearn.tree.DecisionTreeClassifier\n",
        "- Data: X_train, Y_train\n",
        "- **Essential**: explore and optimize DecisionTreeClassifier options   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "W8CWNt_2iZm4"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "'''\n",
        "This part defines the parameters we want to check.\n",
        "since DecisionTreeClassifier expects variavbles (or None). we decided to give him 3 variables, based on params_x_list\n",
        "It's important to remember :\n",
        "x = Features about the current subject\n",
        "Y = binary assunption (0/1) in our case - breast cancer 0 - Not a tumor, 1 = Real tumor\n",
        "in this project - the params we currently use are - max_depth (param_1), min_samples_split (param_2) and criterion (param_3)\n",
        "(took the most common from the docs)\n",
        "'''\n",
        "\n",
        "'''\n",
        "param_1_list : here - we decide the depth of the tree that we want to check. (None == Unlimited)\n",
        "param_2_list : here we decide what is the mininum number of samples that a node must have before splitting into 2 childs.\n",
        "               this param must be > 1 because you need at least 2 samples to be able to split them into 2 groups.\n",
        "param_3_list : for criterion - there are only 2 options.\n",
        "               and we chose to use both in order to get as many results as possible (the more the better :) )\n",
        "               * Gini -  measures how mixed the classes are inside a node.\n",
        "               * entropy - measures uncertainty in a node — coming from information theory.\n",
        "'''\n",
        "\n",
        "param_1_list =[1,2,3,4,5,6,7,8,9,None]\n",
        "param_2_list = [2,3,4,5,6,7,8,9]\n",
        "param_3_list = [\"gini\",\"entropy\"]\n",
        "\n",
        "'''\n",
        "In this part - we create param_grid - which generates all possible combinations of parameters\n",
        "so if for example - if my data is :\n",
        "x = 1,2,3\n",
        "y = 3,4,5\n",
        "z = 6,7,8\n",
        "\n",
        "i will get\n",
        "x1,y1,z1 = 1,3,6\n",
        "x2,y2,z2 = 2,4,7\n",
        "x3,y3,z3 = 3,5,8\n",
        "and so on, untill all is covered.\n",
        "'''\n",
        "param_grid = list(itertools.product(param_1_list, param_2_list, param_3_list))\n",
        "\n",
        "'''\n",
        "here - we actually start to train the model !\n",
        "each time we take a differnt param from the grid, and iterate the entire grid ^\n",
        "'''\n",
        "for param_1, param_2, param_3 in param_grid:\n",
        "    with mlflow.start_run():\n",
        "\n",
        "        '''\n",
        "        this part is perhaps the most imporant in the training session - Because altough we are able to train our model without it -\n",
        "        if we dont log the params - we won't be able to tell which combination from the grid produced the best score !\n",
        "        '''\n",
        "        # Log parameters\n",
        "        mlflow.log_param(\"model_type\", \"DecisionTree\")\n",
        "        mlflow.log_param(\"param_1\", param_1)\n",
        "        mlflow.log_param(\"param_2\", param_2)\n",
        "        mlflow.log_param(\"param_3\", param_3)\n",
        "        '''\n",
        "        Here - the training begin !\n",
        "        the function DecisionTreeClassifier has a lot of options, and it is up to us to decide what to give it,\n",
        "        since we took max_depth, min_samples_split and criterion - we will give it to the function and and each time provide a param from the loop.\n",
        "        '''\n",
        "        # Train the model\n",
        "        d_tree = DecisionTreeClassifier(max_depth=param_1, min_samples_split=param_2, criterion=param_3)\n",
        "        d_tree.fit(X_train, Y_train)\n",
        "        pred = d_tree.predict(X_test)\n",
        "        '''\n",
        "        this part calculate the \"scores\" for the current iteration (in terms of accuracy, precision and recall)\n",
        "        * acc - Out of ALL predictions, how many did the model get right?\n",
        "        * pre - How many “positive” predictions were actually correct?\n",
        "        * rec - How many actual positive cases did we successfully catch?\n",
        "        * f1 -  Balance between precision and recall\n",
        "\n",
        "        '''\n",
        "        acc  = accuracy_score(Y_test, pred)\n",
        "        pre = precision_score(Y_test, pred)\n",
        "        rec  = recall_score(Y_test, pred)\n",
        "        f1   = f1_score(Y_test, pred)\n",
        "\n",
        "\n",
        "        # run test prediction and calculate metrics:\n",
        "        # accuracy_score\n",
        "        # precision_score\n",
        "        # recall_score\n",
        "        # f1_score\n",
        "\n",
        "        '''\n",
        "        Here - we simply log the results to the mlflow.\n",
        "        we do it in order to observe and look at the results the training session produced.\n",
        "        we can see how it is logged in the next code block :)\n",
        "        '''\n",
        "        # Log metrics\n",
        "        mlflow.log_metric(\"accuracy\", acc)\n",
        "        mlflow.log_metric(\"precision_score\", pre)\n",
        "        mlflow.log_metric(\"recall_score\", rec)\n",
        "        mlflow.log_metric(\"f1_score\", f1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X__nmyElkPWs"
      },
      "source": [
        "6. Train model_random_forest\n",
        "- Library: sklearn.ensemble.RandomForestClassifier\n",
        "- Data: X_train, Y_train\n",
        "- **Essential**: explore and optimize RandomForestClassifier options"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "6B4GKjlCkRdT"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "'''\n",
        "Random forest works technically the same as decisionTree in terms of params.\n",
        "it can recieve a lot of different params, I decided to take the most common 3 (from the docs)\n",
        "* param_1_list = n_estimators : Number of trees in the forest\n",
        "* param_2_list = max_depth : depth limit in each tree where None = Infinity\n",
        "* param_3_list = max_features : How many features each tree can use per split.\n",
        "\n",
        "'''\n",
        "param_1_list = [1, 5, 10, 50, 100, 200, 500, 1000]\n",
        "param_2_list = [1,2,3,4,5,6,7,8,9,None]\n",
        "param_3_list = [\"sqrt\", \"log2\"]\n",
        "\n",
        "'''\n",
        "Same as Decision tree - we recieve a grid with all possible combinations.\n",
        "'''\n",
        "param_grid = list(itertools.product(param_1_list, param_2_list, param_3_list))\n",
        "\n",
        "for param_1, param_2, param_3 in param_grid:\n",
        "    with mlflow.start_run():\n",
        "\n",
        "        # Log parameters\n",
        "        mlflow.log_param(\"model_type\", \"RandomForest\")\n",
        "        mlflow.log_param(\"param_1\", param_1)\n",
        "        mlflow.log_param(\"param_2\", param_2)\n",
        "        mlflow.log_param(\"param_3\", param_3)\n",
        "\n",
        "        # Train the model\n",
        "        rf = RandomForestClassifier(n_estimators=param_1, max_depth=param_2, max_features=param_3)\n",
        "        rf.fit(X_train, Y_train)\n",
        "        pred = rf.predict(X_test)\n",
        "\n",
        "\n",
        "\n",
        "        # run test prediction and calculate metrics:\n",
        "        # accuracy_score\n",
        "        # precision_score\n",
        "        # recall_score\n",
        "        # f1_score\n",
        "        acc  = accuracy_score(Y_test, pred)\n",
        "        pre = precision_score(Y_test, pred)\n",
        "        rec  = recall_score(Y_test, pred)\n",
        "        f1   = f1_score(Y_test, pred)\n",
        "\n",
        "\n",
        "        # Log metrics\n",
        "        mlflow.log_metric(\"accuracy\", acc)\n",
        "        mlflow.log_metric(\"precision_score\", pre)\n",
        "        mlflow.log_metric(\"recall_score\", rec)\n",
        "        mlflow.log_metric(\"f1_score\", f1)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qOTlMrDkSBM"
      },
      "source": [
        "7. Train model_adaboost\n",
        "\n",
        "- Library: sklearn.ensemble.AdaBoostClassifier\n",
        "- Data: X_train, Y_train\n",
        "- **Essential**: explore and optimize AdaBoostClassifier options"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Y5VGaDhJkYsL"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "'''\n",
        "Same as DecisionTree and RandomForest - AdaBoost accept various args.\n",
        "I chose the most common args to pick\n",
        "which are -\n",
        "n_estimators\n",
        "learning_rate\n",
        "estimator__min_samples_split\n",
        "'''\n",
        "\n",
        "param_1_list = [1, 5, 10, 50, 100, 200, 500, 1000]\n",
        "param_2_list = [0.01, 0.1, 1.0]\n",
        "param_3_list = [2,5,10]\n",
        "\n",
        "param_grid = list(itertools.product(param_1_list, param_2_list, param_3_list))\n",
        "for param_1, param_2, param_3 in param_grid:\n",
        "    with mlflow.start_run():\n",
        "\n",
        "        # Log parameters\n",
        "        mlflow.log_param(\"model_type\", \"AdaBoost\")\n",
        "        mlflow.log_param(\"param_1\", param_1)\n",
        "        mlflow.log_param(\"param_2\", param_2)\n",
        "        mlflow.log_param(\"param_3\", param_3)\n",
        "        '''\n",
        "        This is a tricky part - param3 is being used from DecisionTree, so when we parse it - we can't simply say estimator=param3.\n",
        "        we need to tell AdaBoostClassifier that we are using a param from DecisionTree\n",
        "        '''\n",
        "        ada = AdaBoostClassifier(n_estimators=param_1, learning_rate=param_2, estimator=DecisionTreeClassifier(min_samples_split=param_3))\n",
        "        ada.fit(X_train, Y_train)\n",
        "        pred = ada.predict(X_test)\n",
        "\n",
        "        # run test prediction and calculate metrics:\n",
        "        # accuracy_score\n",
        "        # precision_score\n",
        "        # recall_score\n",
        "        # f1_score\n",
        "        acc  = accuracy_score(Y_test, pred)\n",
        "        pre = precision_score(Y_test, pred)\n",
        "        rec  = recall_score(Y_test, pred)\n",
        "        f1   = f1_score(Y_test, pred)\n",
        "\n",
        "\n",
        "        # Log metrics\n",
        "        mlflow.log_metric(\"accuracy\", acc)\n",
        "        mlflow.log_metric(\"precision_score\", pre)\n",
        "        mlflow.log_metric(\"recall_score\", rec)\n",
        "        mlflow.log_metric(\"f1_score\", f1)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RryKho_VLGDa"
      },
      "source": [
        "8. Store the result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "zjwA-sE7RAyb",
        "outputId": "a898c0fa-ce90-4f63-cc84-05759fcee4f3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0aa8328f-51b6-488f-a7a2-02c6985a6ad0\", \"student_name_results.xlsx\", 45855)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "df = mlflow.search_runs(experiment_names=[\"trees_hyperparam\"])\n",
        "\n",
        "df = df.drop(columns=[col for col in df.columns if \"time\" in col.lower()], errors=\"ignore\")\n",
        "\n",
        "df.to_excel(\"student_name_results.xlsx\", index=False)\n",
        "\n",
        "files.download(\"student_name_results.xlsx\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUhgM3D5SASk"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}